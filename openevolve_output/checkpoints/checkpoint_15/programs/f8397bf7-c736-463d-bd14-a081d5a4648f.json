{"id": "f8397bf7-c736-463d-bd14-a081d5a4648f", "code": "# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            # Added clamping for intermediate value to prevent potential overflow with large p\n            val = abs(x) / a\n            return math.exp(- (min(val, 10.0))**p ) # Clamp intermediate value\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero to prevent division by zero\n        b = max(b, 1e-9)\n        def f(x):\n            # Added clamping for intermediate value to prevent potential overflow\n            val = x / b\n            return 1.0 / (1.0 + min(val, 10.0)**2) # Clamp intermediate value\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            # Combined safe versions of supergauss and lorentz components.\n            # Added clamping for intermediate values.\n            gauss_term = math.exp(- (min(a, 10.0)*x*x))\n            lorentz_term = 1.0 / (1.0 + min(x, 10.0)**2) # Implicit b=1.0\n            return (1-r)*gauss_term + r*lorentz_term\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            # Added clamping for intermediate value to prevent potential overflow\n            return math.exp(- min(a, 10.0)*x*x) # Clamp intermediate value\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust parameter ranges for more variety and safety\n        # Increased p range slightly, reduced 'a' range slightly.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.7, 2.0), \"p\": random.uniform(3.0, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjust parameter ranges for more variety and safety\n        # Reduced 'b' range slightly.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.7, 3.0)}\n    else:\n        # Slightly adjust parameter ranges for more variety and safety\n        # Adjusted 'r' range slightly.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.7, 2.0), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params", "language": "python", "parent_id": "8183b53b-8277-4632-bb35-7de905e85c51", "generation": 2, "timestamp": 1763628746.039875, "iteration_found": 8, "metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "island": 0}, "prompts": {"full_rewrite_user": {"system": "You are an expert in functional analysis and numerical methods.\nProduce small, numerically-safe mutations of the candidate returned by search_algorithm().\nPrefer parameter changes (modify numeric values in the params dict or tweak small constants).\nDo NOT output code that divides by zero or returns NaN/Inf, and do not use heavy Monte-Carlo loops.\nWhen proposing new candidates, either:\n  - return a modified params dictionary (e.g., {\"type\":\"supergauss\",\"a\":1.2,\"p\":4.0}), OR\n  - provide a short, valid Python function f(x) that evaluates safely on [-6,6].\n", "user": "# Current Program Information\n- Fitness: 100.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 100.0000\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 6.0)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n### Program 2 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure no division by zero if a is very small, though search_algorithm prevents this.\n            # Also, ensure the exponentiation is safe.\n            val = abs(x) / max(a, 1e-9) # Prevent division by zero\n            return math.exp(- (val**p) )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            # Ensure no division by zero if b is very small.\n            return 1.0 / (1.0 + (x/max(b, 1e-9))**2) # Prevent division by zero\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            # Combine safe versions of supergauss and lorentz components.\n            gauss_term = math.exp(-max(a, 1e-9)*x*x)\n            lorentz_term = 1.0 / (1.0 + (x/max(0.1, 1e-9))**2) # Using a small constant for b in lorentz part\n            return (1-r)*gauss_term + r*lorentz_term\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-max(a, 1e-9)*x*x) # Prevent division by zero\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore more diverse shapes.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.3, 2.5), \"p\": random.uniform(2.5, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjust range for b.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.3, 3.5)}\n    else:\n        # Slightly adjust ranges for a and r.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.3, 2.5), \"r\": random.uniform(0.1, 0.9)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n### Program 3 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero to prevent division by zero\n        b = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 2.5), \"p\": random.uniform(3.1, 6.5)}\n    elif choice == \"lorentz\":\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 3.5)}\n    else:\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 2.5), \"r\": random.uniform(0.25, 0.75)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to avoid division by zero\n            if a == 0:\n                return 0.0\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            # Ensure b is not zero to avoid division by zero\n            if b == 0:\n                return 1.0 # or handle as an error, but for safety, return a non-singular value\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            # Ensure a and b (implicitly 1.0 in the lorentz part) are not zero\n            term1 = 0.0\n            if a != 0:\n                term1 = (1-r)*math.exp(-a*x*x)\n            term2 = 0.0\n            # The lorentz part has an implicit b=1.0\n            if 1.0 != 0:\n                term2 = r/(1.0 + x*x)\n            return term1 + term2\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            # Ensure a is not zero\n            if a == 0:\n                return 0.0\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to avoid extreme values and ensure numerical stability\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 1.8), \"p\": random.uniform(3.1, 5.5)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 2.5)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 1.8), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Alternative approach to combined_score, Alternative approach to I1\n\n### Program D2 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to avoid division by zero.\n            # If a is very small, it can lead to overflow, so clamp it.\n            safe_a = max(a, 1e-6)\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to avoid division by zero.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to avoid division by zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to avoid division by zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore different shapes.\n        # Increase p range for more pronounced super-Gaussian shapes.\n        # Ensure 'a' is not too close to zero.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 1.5), \"p\": random.uniform(3.0, 8.0)}\n    elif choice == \"lorentz\":\n        # Ensure 'b' is not too close to zero.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.5)}\n    else: # mixed\n        # Ensure 'a' is not too close to zero.\n        # Keep 'r' in a range that balances the two components.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.5), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Alternative approach to combined_score, Alternative approach to I1\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 6.0)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n\n```\nUnique approach: Excellent combined_score (100.000), Excellent I1 (100.000), Excellent I2 (100.000)\n\n### Inspiration 2 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure no division by zero if a is very small, though search_algorithm prevents this.\n            # Also, ensure the exponentiation is safe.\n            val = abs(x) / max(a, 1e-9) # Prevent division by zero\n            return math.exp(- (val**p) )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            # Ensure no division by zero if b is very small.\n            return 1.0 / (1.0 + (x/max(b, 1e-9))**2) # Prevent division by zero\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            # Combine safe versions of supergauss and lorentz components.\n            gauss_term = math.exp(-max(a, 1e-9)*x*x)\n            lorentz_term = 1.0 / (1.0 + (x/max(0.1, 1e-9))**2) # Using a small constant for b in lorentz part\n            return (1-r)*gauss_term + r*lorentz_term\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-max(a, 1e-9)*x*x) # Prevent division by zero\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore more diverse shapes.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.3, 2.5), \"p\": random.uniform(2.5, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjust range for b.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.3, 3.5)}\n    else:\n        # Slightly adjust ranges for a and r.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.3, 2.5), \"r\": random.uniform(0.1, 0.9)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nUnique approach: Modification: Full rewrite, Excellent combined_score (100.000), Excellent I1 (100.000)\n\n### Inspiration 3 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to avoid division by zero\n            if a == 0:\n                return 0.0\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            # Ensure b is not zero to avoid division by zero\n            if b == 0:\n                return 1.0 # or handle as an error, but for safety, return a non-singular value\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            # Ensure a and b (implicitly 1.0 in the lorentz part) are not zero\n            term1 = 0.0\n            if a != 0:\n                term1 = (1-r)*math.exp(-a*x*x)\n            term2 = 0.0\n            # The lorentz part has an implicit b=1.0\n            if 1.0 != 0:\n                term2 = r/(1.0 + x*x)\n            return term1 + term2\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            # Ensure a is not zero\n            if a == 0:\n                return 0.0\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to avoid extreme values and ensure numerical stability\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 1.8), \"p\": random.uniform(3.1, 5.5)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 2.5)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 1.8), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nUnique approach: Modification: Full rewrite, Excellent combined_score (100.000), Excellent I1 (100.000)\n\n# Current Program\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero to prevent division by zero\n        b = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 2.5), \"p\": random.uniform(3.1, 6.5)}\n    elif choice == \"lorentz\":\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 3.5)}\n    else:\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 2.5), \"r\": random.uniform(0.25, 0.75)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            # Added clamping for intermediate value to prevent potential overflow with large p\n            val = abs(x) / a\n            return math.exp(- (min(val, 10.0))**p ) # Clamp intermediate value\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero to prevent division by zero\n        b = max(b, 1e-9)\n        def f(x):\n            # Added clamping for intermediate value to prevent potential overflow\n            val = x / b\n            return 1.0 / (1.0 + min(val, 10.0)**2) # Clamp intermediate value\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            # Combined safe versions of supergauss and lorentz components.\n            # Added clamping for intermediate values.\n            gauss_term = math.exp(- (min(a, 10.0)*x*x))\n            lorentz_term = 1.0 / (1.0 + min(x, 10.0)**2) # Implicit b=1.0\n            return (1-r)*gauss_term + r*lorentz_term\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            # Added clamping for intermediate value to prevent potential overflow\n            return math.exp(- min(a, 10.0)*x*x) # Clamp intermediate value\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust parameter ranges for more variety and safety\n        # Increased p range slightly, reduced 'a' range slightly.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.7, 2.0), \"p\": random.uniform(3.0, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjust parameter ranges for more variety and safety\n        # Reduced 'b' range slightly.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.7, 3.0)}\n    else:\n        # Slightly adjust parameter ranges for more variety and safety\n        # Adjusted 'r' range slightly.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.7, 2.0), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}