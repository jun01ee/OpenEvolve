{"id": "4f18a928-770a-4ef4-a20a-0ba8eb14fd05", "code": "# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure 'a' is not too close to zero to prevent division by zero or large numbers.\n            safe_a = max(a, 1e-6)\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not too close to zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not too close to zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges for 'a' and 'p' to explore a wider variety of super-Gaussian shapes.\n        # Ensure 'a' is not excessively small.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.7, 1.8), \"p\": random.uniform(3.0, 7.0)}\n    elif choice == \"lorentz\":\n        # Adjust range for 'b' to explore different widths of the Lorentz function.\n        # Ensure 'b' is not excessively small.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.7, 2.5)}\n    else: # mixed\n        # Adjust ranges for 'a' and 'r' to better balance the Gaussian and Lorentz components.\n        # Ensure 'a' is not excessively small.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.7, 1.8), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params", "language": "python", "parent_id": "22502a98-6825-4603-9942-471bd705173d", "generation": 1, "timestamp": 1763628741.155385, "iteration_found": 5, "metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "island": 0}, "prompts": {"full_rewrite_user": {"system": "You are an expert in functional analysis and numerical methods.\nProduce small, numerically-safe mutations of the candidate returned by search_algorithm().\nPrefer parameter changes (modify numeric values in the params dict or tweak small constants).\nDo NOT output code that divides by zero or returns NaN/Inf, and do not use heavy Monte-Carlo loops.\nWhen proposing new candidates, either:\n  - return a modified params dictionary (e.g., {\"type\":\"supergauss\",\"a\":1.2,\"p\":4.0}), OR\n  - provide a short, valid Python function f(x) that evaluates safely on [-6,6].\n", "user": "# Current Program Information\n- Fitness: 100.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 100.0000\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 6.0)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n### Program 2 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to avoid division by zero.\n            # If a is very small, it can lead to overflow, so clamp it.\n            safe_a = max(a, 1e-6)\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to avoid division by zero.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to avoid division by zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to avoid division by zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore different shapes.\n        # Increase p range for more pronounced super-Gaussian shapes.\n        # Ensure 'a' is not too close to zero.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 1.5), \"p\": random.uniform(3.0, 8.0)}\n    elif choice == \"lorentz\":\n        # Ensure 'b' is not too close to zero.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.5)}\n    else: # mixed\n        # Ensure 'a' is not too close to zero.\n        # Keep 'r' in a range that balances the two components.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.5), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to avoid division by zero.\n            # If a is very small, it can lead to overflow, so clamp it.\n            safe_a = max(a, 1e-6)\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to avoid division by zero.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to avoid division by zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to avoid division by zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore different shapes.\n        # Increase p range for more pronounced super-Gaussian shapes.\n        # Ensure 'a' is not too close to zero.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 1.5), \"p\": random.uniform(3.0, 8.0)}\n    elif choice == \"lorentz\":\n        # Ensure 'b' is not too close to zero.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.5)}\n    else: # mixed\n        # Ensure 'a' is not too close to zero.\n        # Keep 'r' in a range that balances the two components.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.5), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nUnique approach: Modification: Full rewrite, Excellent combined_score (100.000), Excellent I1 (100.000)\n\n# Current Program\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 6.0)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure 'a' is not too close to zero to prevent division by zero or large numbers.\n            safe_a = max(a, 1e-6)\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not too close to zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not too close to zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges for 'a' and 'p' to explore a wider variety of super-Gaussian shapes.\n        # Ensure 'a' is not excessively small.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.7, 1.8), \"p\": random.uniform(3.0, 7.0)}\n    elif choice == \"lorentz\":\n        # Adjust range for 'b' to explore different widths of the Lorentz function.\n        # Ensure 'b' is not excessively small.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.7, 2.5)}\n    else: # mixed\n        # Adjust ranges for 'a' and 'r' to better balance the Gaussian and Lorentz components.\n        # Ensure 'a' is not excessively small.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.7, 1.8), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}