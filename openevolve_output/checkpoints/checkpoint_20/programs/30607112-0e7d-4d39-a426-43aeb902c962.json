{"id": "30607112-0e7d-4d39-a426-43aeb902c962", "code": "# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to prevent division by zero and p is not too small\n            safe_a = max(a, 1e-9)\n            safe_p = max(p, 0.1) # Ensure p is positive and not extremely small\n            # Added safety for large exponents to prevent overflow\n            exponent = (abs(x)/safe_a)**safe_p\n            return math.exp(-min(exponent, 700.0)) # Cap exponent to prevent overflow\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        safe_b = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero and r is within [0, 1]\n        safe_a = max(a, 1e-9)\n        safe_r = max(0.0, min(1.0, r))\n        def f(x):\n            exp_term = math.exp(-safe_a*x*x)\n            return (1-safe_r)*exp_term + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero\n        safe_a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for a and p, ensuring p is not too close to 2\n        # Increased range for 'a' and 'p' to explore more super-gaussian shapes\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(1.5, 6.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjusted range for b, ensuring it's positive\n        # Expanded range for 'b' to explore broader Lorentz functions\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.3, 3.0)}\n    else:\n        # Slightly adjusted ranges for a and r, ensuring r is within reasonable bounds\n        # Slightly wider range for 'a' and 'r' to explore more mixed function behaviors\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.4, 1.8), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params", "language": "python", "parent_id": "72929b17-7915-4880-8607-e542a26d428b", "generation": 3, "timestamp": 1763629581.05728, "iteration_found": 20, "metrics": {"error": 0.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"error": 0.0}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "You are an expert in functional analysis and numerical methods.\nProduce small, numerically-safe mutations of the candidate returned by search_algorithm().\nPrefer parameter changes (modify numeric values in the params dict or tweak small constants).\nDo NOT output code that divides by zero or returns NaN/Inf, and do not use heavy Monte-Carlo loops.\nWhen proposing new candidates, either:\n  - return a modified params dictionary (e.g., {\"type\":\"supergauss\",\"a\":1.2,\"p\":4.0}), OR\n  - provide a short, valid Python function f(x) that evaluates safely on [-6,6].\nIMPORTANT:\n  - Always return ONLY executable Python code.\n  - Do not return text explanations, comments, or natural language.\n", "user": "# Current Program Information\n- Fitness: 0.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 0.0000\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: error: 0.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to prevent division by zero and p is not too small\n            safe_a = max(a, 1e-9)\n            safe_p = max(p, 0.1) # Ensure p is positive and not extremely small\n            return math.exp(- (abs(x)/safe_a)**safe_p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        safe_b = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero and r is within [0, 1]\n        safe_a = max(a, 1e-9)\n        safe_r = max(0.0, min(1.0, r))\n        def f(x):\n            return (1-safe_r)*math.exp(-safe_a*x*x) + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero\n        safe_a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for a and p, ensuring p is not too close to 2\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.7, 1.7), \"p\": random.uniform(2.2, 5.5)}\n    elif choice == \"lorentz\":\n        # Slightly adjusted range for b, ensuring it's positive\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.0)}\n    else:\n        # Slightly adjusted ranges for a and r, ensuring r is within reasonable bounds\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.5), \"r\": random.uniform(0.4, 0.6)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on error (0.0000)\n\n\n\n# Current Program\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to prevent division by zero and p is not too small\n            safe_a = max(a, 1e-9)\n            safe_p = max(p, 0.1) # Ensure p is positive and not extremely small\n            return math.exp(- (abs(x)/safe_a)**safe_p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        safe_b = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero and r is within [0, 1]\n        safe_a = max(a, 1e-9)\n        safe_r = max(0.0, min(1.0, r))\n        def f(x):\n            return (1-safe_r)*math.exp(-safe_a*x*x) + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero\n        safe_a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for a and p, ensuring p is not too close to 2\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.7, 1.7), \"p\": random.uniform(2.2, 5.5)}\n    elif choice == \"lorentz\":\n        # Slightly adjusted range for b, ensuring it's positive\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.0)}\n    else:\n        # Slightly adjusted ranges for a and r, ensuring r is within reasonable bounds\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.5), \"r\": random.uniform(0.4, 0.6)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to prevent division by zero and p is not too small\n            safe_a = max(a, 1e-9)\n            safe_p = max(p, 0.1) # Ensure p is positive and not extremely small\n            # Added safety for large exponents to prevent overflow\n            exponent = (abs(x)/safe_a)**safe_p\n            return math.exp(-min(exponent, 700.0)) # Cap exponent to prevent overflow\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        safe_b = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero and r is within [0, 1]\n        safe_a = max(a, 1e-9)\n        safe_r = max(0.0, min(1.0, r))\n        def f(x):\n            exp_term = math.exp(-safe_a*x*x)\n            return (1-safe_r)*exp_term + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero\n        safe_a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for a and p, ensuring p is not too close to 2\n        # Increased range for 'a' and 'p' to explore more super-gaussian shapes\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(1.5, 6.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjusted range for b, ensuring it's positive\n        # Expanded range for 'b' to explore broader Lorentz functions\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.3, 3.0)}\n    else:\n        # Slightly adjusted ranges for a and r, ensuring r is within reasonable bounds\n        # Slightly wider range for 'a' and 'r' to explore more mixed function behaviors\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.4, 1.8), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}