{"id": "92351dcc-b254-4954-b686-5dd1c7885d91", "code": "# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to prevent division by zero\n        # Use a slightly larger epsilon to be more robust\n        safe_a = max(a, 1e-7)\n        # Use math.pow for potentially better numerical stability with exponents\n        # Cap p to prevent extremely large values that might cause overflow\n        safe_p = min(p, 10.0)\n        def f(x):\n            return math.exp(- math.pow(abs(x)/safe_a, safe_p) )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        safe_b = max(b, 1e-7)\n        def f(x):\n            # The denominator 1.0 + (x/safe_b)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + math.pow(x/safe_b, 2))\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to prevent division by zero in the Gaussian term\n        safe_a = max(a, 1e-7)\n        # Ensure r is within [0, 1] for valid mixing\n        r_clamped = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is close to 1\n        one_minus_r_safe = max(1.0 - r_clamped, 1e-7)\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_r_safe*math.exp(-safe_a*x*x) + r_clamped/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to prevent division by zero\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly wider ranges for 'a' and 'p' to encourage exploration of the super-gaussian shape.\n        # 'a' range is kept reasonable, 'p' range favors values further from 2.\n        # Increased lower bound for 'a' to avoid extremely narrow peaks.\n        # Cap p to prevent potential overflow issues in math.pow.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.5), \"p\": random.uniform(2.5, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjusted 'b' range to explore different widths for the Lorentz function.\n        # Slightly increased range for 'b' to explore broader Lorentzian shapes.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.5)}\n    else: # mixed\n        # Slightly adjusted 'a' and 'r' ranges to explore different mixing ratios and Gaussian widths.\n        # 'r' range is kept away from the exact extremes to ensure both components contribute.\n        # Ensured 'r' is not too close to 0 or 1 to maintain a mix.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.5), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params", "language": "python", "parent_id": "0f45cf38-aef0-4c0e-ab60-803cf6515b2c", "generation": 3, "timestamp": 1763629277.4653199, "iteration_found": 17, "metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "island": 0}, "prompts": {"full_rewrite_user": {"system": "You are an expert in functional analysis and numerical methods.\nProduce small, numerically-safe mutations of the candidate returned by search_algorithm().\nPrefer parameter changes (modify numeric values in the params dict or tweak small constants).\nDo NOT output code that divides by zero or returns NaN/Inf, and do not use heavy Monte-Carlo loops.\nWhen proposing new candidates, either:\n  - return a modified params dictionary (e.g., {\"type\":\"supergauss\",\"a\":1.2,\"p\":4.0}), OR\n  - provide a short, valid Python function f(x) that evaluates safely on [-6,6].\n", "user": "# Current Program Information\n- Fitness: 100.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 100.0000\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9) # Use a slightly smaller epsilon for broader range\n        def f(x):\n            return math.exp(- (abs(x)/a_safe)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        b_safe = max(b, 1e-9) # Use a slightly smaller epsilon for broader range\n        def f(x):\n            return 1.0 / (1.0 + (x/b_safe)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to prevent division by zero in the Gaussian term\n        a_safe = max(a, 1e-9) # Use a slightly smaller epsilon for broader range\n        # Ensure r is within [0, 1] for valid mixing\n        r_clamped = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is close to 1\n        one_minus_r_safe = max(1.0 - r_clamped, 1e-9)\n        def f(x):\n            return one_minus_r_safe*math.exp(-a_safe*x*x) + r_clamped/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9) # Use a slightly smaller epsilon for broader range\n        def f(x):\n            return math.exp(-a_safe*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to encourage exploration, leaning towards higher p for more super-gaussian behavior\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 7.5)}\n    elif choice == \"lorentz\":\n        # Slightly wider range for b\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.3, 4.0)}\n    else: # mixed\n        # Wider range for r, encouraging exploration of extremes\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.05, 0.95)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n### Program 2 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9)\n        def f(x):\n            return math.exp(- (abs(x)/a_safe)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        b_safe = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/b_safe)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to prevent division by zero in the Gaussian term\n        a_safe = max(a, 1e-9)\n        # Ensure r is within [0, 1] for valid mixing\n        r_clamped = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is close to 1\n        one_minus_r_safe = max(1.0 - r_clamped, 1e-9)\n        def f(x):\n            return one_minus_r_safe*math.exp(-a_safe*x*x) + r_clamped/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9)\n        def f(x):\n            return math.exp(-a_safe*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to encourage exploration around\n        # potentially good values, while still allowing some variation.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 2.0), \"p\": random.uniform(2.8, 6.0)}\n    elif choice == \"lorentz\":\n        # Narrower range for 'b' to avoid extreme Lorentz shapes.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 3.0)}\n    else: # mixed\n        # Adjusted ranges for 'a' and 'r' to favor values that create smoother transitions.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n### Program 3 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9) # Using a slightly smaller epsilon for safety\n        def f(x):\n            return math.exp(- (abs(x)/a_safe)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        b_safe = max(b, 1e-9) # Using a slightly smaller epsilon for safety\n        def f(x):\n            # The denominator 1.0 + (x/b_safe)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + (x/b_safe)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to prevent division by zero in the Gaussian term\n        a_safe = max(a, 1e-9) # Using a slightly smaller epsilon for safety\n        # Ensure r is within [0, 1] for valid mixing\n        r_safe = max(0.0, min(1.0, r))\n        one_minus_r_safe = 1.0 - r_safe\n        # Ensure one_minus_r_safe is not zero if r is exactly 1.0\n        if one_minus_r_safe < 1e-9:\n            one_minus_r_safe = 1e-9\n\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_r_safe*math.exp(-a_safe*x*x) + r_safe/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9) # Using a slightly smaller epsilon for safety\n        def f(x):\n            return math.exp(-a_safe*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly tighter ranges for 'a' and 'p' to encourage more focused exploration\n        # around potentially good values, while still allowing some variation.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 2.0), \"p\": random.uniform(2.8, 6.0)}\n    elif choice == \"lorentz\":\n        # Narrower range for 'b' to avoid extreme Lorentz shapes.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 3.0)}\n    else: # mixed\n        # Adjusted ranges for 'a' and 'r' to favor values that create smoother transitions.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to prevent division by zero\n        # Increased epsilon slightly for more robust behavior near zero\n        safe_a = max(a, 1e-8)\n        def f(x):\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        # Increased epsilon slightly for more robust behavior near zero\n        safe_b = max(b, 1e-8)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to prevent division by zero in the Gaussian term\n        # Increased epsilon slightly for more robust behavior near zero\n        safe_a = max(a, 1e-8)\n        # Ensure r is within [0, 1] for valid mixing\n        r_clamped = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is close to 1\n        one_minus_r_safe = max(1.0 - r_clamped, 1e-8)\n        def f(x):\n            return one_minus_r_safe*math.exp(-safe_a*x*x) + r_clamped/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to prevent division by zero\n        # Increased epsilon slightly for more robust behavior near zero\n        safe_a = max(a, 1e-8)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to encourage exploration of the super-gaussian shape.\n        # 'a' range is kept reasonable, 'p' range favors values further from 2.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 1.8), \"p\": random.uniform(2.8, 6.5)}\n    elif choice == \"lorentz\":\n        # Slightly adjusted 'b' range to explore different widths for the Lorentz function.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.8)}\n    else: # mixed\n        # Slightly adjusted 'a' and 'r' ranges to explore different mixing ratios and Gaussian widths.\n        # 'r' range is kept away from the exact extremes to ensure both components contribute.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.8), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Alternative approach to combined_score, Alternative approach to I1\n\n### Program D2 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is positive to avoid division by zero or issues with abs(x)/a\n        safe_a = max(a, 1e-9)\n        def f(x):\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero to avoid division by zero\n        safe_b = max(b, 1e-9)\n        def f(x):\n            # The denominator 1.0 + (x/safe_b)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is positive to avoid division by zero in the Gaussian term\n        safe_a = max(a, 1e-9)\n        # Ensure 'r' is within [0, 1] for valid mixing\n        safe_r = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not zero for the respective term\n        one_minus_safe_r = max(1.0 - safe_r, 1e-9)\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_safe_r*math.exp(-safe_a*x*x) + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is positive to avoid division by zero\n        safe_a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to encourage exploration\n        # 'a' is kept away from zero, 'p' explores values further from 2.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(2.5, 7.0)}\n    elif choice == \"lorentz\":\n        # Adjusted 'b' range to explore values away from zero.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else: # mixed\n        # Adjusted 'a' and 'r' ranges. 'a' is kept away from zero, 'r' is kept within [0,1].\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Alternative approach to combined_score, Alternative approach to I1\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to avoid division by zero\n        safe_a = max(a, 1e-9)\n        # Use math.pow for potentially better numerical stability with exponents\n        # Added a check for p to ensure it's not excessively large, which could lead to overflow.\n        safe_p = min(p, 10.0) # Cap p to avoid extreme values.\n        def f(x):\n            return math.exp(- math.pow(abs(x)/safe_a, safe_p) )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to avoid division by zero\n        safe_b = max(b, 1e-9)\n        def f(x):\n            # Use math.pow for consistency, though x*x is fine\n            # The denominator is always >= 1, so no division by zero issues here.\n            return 1.0 / (1.0 + math.pow(x/safe_b, 2))\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to avoid division by zero\n        safe_a = max(a, 1e-9)\n        # Ensure r is within [0, 1]\n        r_clamped = max(0.0, min(1.0, r))\n        # Ensure (1-r_clamped) is not too close to zero if r is 1.\n        one_minus_r_safe = max(1.0 - r_clamped, 1e-9)\n        def f(x):\n            # Denominator 1.0 + x*x is always >= 1.0.\n            return one_minus_r_safe*math.exp(-safe_a*x*x) + r_clamped/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to avoid division by zero\n        safe_a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to explore more values.\n        # Increased lower bound for 'a' to avoid extremely narrow peaks.\n        # Capped 'p' range to prevent potential overflow issues in math.pow.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.5), \"p\": random.uniform(2.5, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly increased range for 'b' to explore broader Lorentzian shapes.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.5)}\n    else:\n        # Slightly adjusted range for 'a' and 'r'.\n        # Ensured 'r' is not too close to 0 or 1 to maintain a mix.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.5), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nUnique approach: Modification: Full rewrite, Excellent combined_score (100.000), Excellent I1 (100.000)\n\n### Inspiration 2 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 6.0)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n\n```\nUnique approach: Excellent combined_score (100.000), Excellent I1 (100.000), Excellent I2 (100.000)\n\n### Inspiration 3 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9)\n        def f(x):\n            return math.exp(- (abs(x)/a_safe)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        b_safe = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/b_safe)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to prevent division by zero in the Gaussian term\n        a_safe = max(a, 1e-9)\n        # Ensure r is within [0, 1] for valid mixing\n        r_clamped = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is close to 1\n        one_minus_r_safe = max(1.0 - r_clamped, 1e-9)\n        def f(x):\n            return one_minus_r_safe*math.exp(-a_safe*x*x) + r_clamped/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9)\n        def f(x):\n            return math.exp(-a_safe*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to encourage exploration around\n        # potentially good values, while still allowing some variation.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 2.0), \"p\": random.uniform(2.8, 6.0)}\n    elif choice == \"lorentz\":\n        # Narrower range for 'b' to avoid extreme Lorentz shapes.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 3.0)}\n    else: # mixed\n        # Adjusted ranges for 'a' and 'r' to favor values that create smoother transitions.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nUnique approach: Modification: Full rewrite, Excellent combined_score (100.000), Excellent I1 (100.000)\n\n# Current Program\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9) # Using a slightly smaller epsilon for safety\n        def f(x):\n            return math.exp(- (abs(x)/a_safe)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        b_safe = max(b, 1e-9) # Using a slightly smaller epsilon for safety\n        def f(x):\n            # The denominator 1.0 + (x/b_safe)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + (x/b_safe)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to prevent division by zero in the Gaussian term\n        a_safe = max(a, 1e-9) # Using a slightly smaller epsilon for safety\n        # Ensure r is within [0, 1] for valid mixing\n        r_safe = max(0.0, min(1.0, r))\n        one_minus_r_safe = 1.0 - r_safe\n        # Ensure one_minus_r_safe is not zero if r is exactly 1.0\n        if one_minus_r_safe < 1e-9:\n            one_minus_r_safe = 1e-9\n\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_r_safe*math.exp(-a_safe*x*x) + r_safe/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to prevent division by zero\n        a_safe = max(a, 1e-9) # Using a slightly smaller epsilon for safety\n        def f(x):\n            return math.exp(-a_safe*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly tighter ranges for 'a' and 'p' to encourage more focused exploration\n        # around potentially good values, while still allowing some variation.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 2.0), \"p\": random.uniform(2.8, 6.0)}\n    elif choice == \"lorentz\":\n        # Narrower range for 'b' to avoid extreme Lorentz shapes.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 3.0)}\n    else: # mixed\n        # Adjusted ranges for 'a' and 'r' to favor values that create smoother transitions.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure a is not zero to prevent division by zero\n        # Use a slightly larger epsilon to be more robust\n        safe_a = max(a, 1e-7)\n        # Use math.pow for potentially better numerical stability with exponents\n        # Cap p to prevent extremely large values that might cause overflow\n        safe_p = min(p, 10.0)\n        def f(x):\n            return math.exp(- math.pow(abs(x)/safe_a, safe_p) )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to prevent division by zero\n        safe_b = max(b, 1e-7)\n        def f(x):\n            # The denominator 1.0 + (x/safe_b)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + math.pow(x/safe_b, 2))\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to prevent division by zero in the Gaussian term\n        safe_a = max(a, 1e-7)\n        # Ensure r is within [0, 1] for valid mixing\n        r_clamped = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is close to 1\n        one_minus_r_safe = max(1.0 - r_clamped, 1e-7)\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_r_safe*math.exp(-safe_a*x*x) + r_clamped/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to prevent division by zero\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly wider ranges for 'a' and 'p' to encourage exploration of the super-gaussian shape.\n        # 'a' range is kept reasonable, 'p' range favors values further from 2.\n        # Increased lower bound for 'a' to avoid extremely narrow peaks.\n        # Cap p to prevent potential overflow issues in math.pow.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.5), \"p\": random.uniform(2.5, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjusted 'b' range to explore different widths for the Lorentz function.\n        # Slightly increased range for 'b' to explore broader Lorentzian shapes.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.5)}\n    else: # mixed\n        # Slightly adjusted 'a' and 'r' ranges to explore different mixing ratios and Gaussian widths.\n        # 'r' range is kept away from the exact extremes to ensure both components contribute.\n        # Ensured 'r' is not too close to 0 or 1 to maintain a mix.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.5), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}