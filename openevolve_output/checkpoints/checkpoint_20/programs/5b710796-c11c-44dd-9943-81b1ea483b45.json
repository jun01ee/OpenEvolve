{"id": "5b710796-c11c-44dd-9943-81b1ea483b45", "code": "# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero or too close to zero to prevent division by zero or overflow.\n        # Using max with a small epsilon for safety.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero or too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-7)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero or too close to zero.\n        safe_a = max(a, 1e-7)\n        # The lorentz part has an implicit b=1.0, which is safe.\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero or too close to zero.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust parameter ranges for more variety and safety.\n        # Increase the upper bound of 'p' slightly to explore sharper super-Gaussians.\n        # Ensure 'a' is not too close to zero.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjust parameter ranges for more variety and safety.\n        # Expand the range for 'b' to explore wider Lorentz profiles.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else: # mixed\n        # Slightly adjust parameter ranges for more variety and safety.\n        # Broaden the range for 'r' to explore different balances between Gaussian and Lorentz.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params", "language": "python", "parent_id": "8183b53b-8277-4632-bb35-7de905e85c51", "generation": 2, "timestamp": 1763628751.771107, "iteration_found": 11, "metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "island": 0}, "prompts": {"full_rewrite_user": {"system": "You are an expert in functional analysis and numerical methods.\nProduce small, numerically-safe mutations of the candidate returned by search_algorithm().\nPrefer parameter changes (modify numeric values in the params dict or tweak small constants).\nDo NOT output code that divides by zero or returns NaN/Inf, and do not use heavy Monte-Carlo loops.\nWhen proposing new candidates, either:\n  - return a modified params dictionary (e.g., {\"type\":\"supergauss\",\"a\":1.2,\"p\":4.0}), OR\n  - provide a short, valid Python function f(x) that evaluates safely on [-6,6].\n", "user": "# Current Program Information\n- Fitness: 100.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 100.0000\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Unknown changes\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero or too close to zero to prevent division by zero or overflow.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero or too close to zero to prevent division by zero or overflow.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero or too close to zero.\n        safe_a = max(a, 1e-6)\n        # The lorentz part has an implicit b=1.0, which is safe.\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero or too close to zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore different shapes and ensure numerical stability.\n        # Increase p range for more pronounced super-Gaussian shapes.\n        # Ensure 'a' is not too close to zero.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 1.5), \"p\": random.uniform(3.0, 8.0)}\n    elif choice == \"lorentz\":\n        # Ensure 'b' is not too close to zero.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.5)}\n    else: # mixed\n        # Ensure 'a' is not too close to zero.\n        # Keep 'r' in a range that balances the two components.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.5), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n### Program 2 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 6.0)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n### Program 3 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure no division by zero if a is very small, though search_algorithm prevents this.\n            # Also, ensure the exponentiation is safe.\n            val = abs(x) / max(a, 1e-9) # Prevent division by zero\n            return math.exp(- (val**p) )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            # Ensure no division by zero if b is very small.\n            return 1.0 / (1.0 + (x/max(b, 1e-9))**2) # Prevent division by zero\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            # Combine safe versions of supergauss and lorentz components.\n            gauss_term = math.exp(-max(a, 1e-9)*x*x)\n            lorentz_term = 1.0 / (1.0 + (x/max(0.1, 1e-9))**2) # Using a small constant for b in lorentz part\n            return (1-r)*gauss_term + r*lorentz_term\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-max(a, 1e-9)*x*x) # Prevent division by zero\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore more diverse shapes.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.3, 2.5), \"p\": random.uniform(2.5, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjust range for b.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.3, 3.5)}\n    else:\n        # Slightly adjust ranges for a and r.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.3, 2.5), \"r\": random.uniform(0.1, 0.9)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure a is not zero to avoid division by zero.\n            # If a is very small, it can lead to overflow, so clamp it.\n            safe_a = max(a, 1e-6)\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure b is not zero to avoid division by zero.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure a is not zero to avoid division by zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure a is not zero to avoid division by zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore different shapes.\n        # Increase p range for more pronounced super-Gaussian shapes.\n        # Ensure 'a' is not too close to zero.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 1.5), \"p\": random.uniform(3.0, 8.0)}\n    elif choice == \"lorentz\":\n        # Ensure 'b' is not too close to zero.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.5)}\n    else: # mixed\n        # Ensure 'a' is not too close to zero.\n        # Keep 'r' in a range that balances the two components.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.5), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Alternative approach to combined_score, Alternative approach to I1\n\n### Program D2 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero to prevent division by zero\n        b = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 2.5), \"p\": random.uniform(3.1, 6.5)}\n    elif choice == \"lorentz\":\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 3.5)}\n    else:\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 2.5), \"r\": random.uniform(0.25, 0.75)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Alternative approach to combined_score, Alternative approach to I1\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 6.0)}\n    elif choice == \"lorentz\":\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else:\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n\n```\nUnique approach: Excellent combined_score (100.000), Excellent I1 (100.000), Excellent I2 (100.000)\n\n### Inspiration 2 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero or too close to zero to prevent division by zero or overflow.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero or too close to zero to prevent division by zero or overflow.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero or too close to zero.\n        safe_a = max(a, 1e-6)\n        # The lorentz part has an implicit b=1.0, which is safe.\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero or too close to zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges to explore different shapes and ensure numerical stability.\n        # Increase p range for more pronounced super-Gaussian shapes.\n        # Ensure 'a' is not too close to zero.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 1.5), \"p\": random.uniform(3.0, 8.0)}\n    elif choice == \"lorentz\":\n        # Ensure 'b' is not too close to zero.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 2.5)}\n    else: # mixed\n        # Ensure 'a' is not too close to zero.\n        # Keep 'r' in a range that balances the two components.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 1.5), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nUnique approach: Modification: Full rewrite, Excellent combined_score (100.000), Excellent I1 (100.000)\n\n### Inspiration 3 (Score: 100.0000, Type: High-Performer)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        def f(x):\n            # Ensure 'a' is not too close to zero to prevent division by zero or large numbers.\n            safe_a = max(a, 1e-6)\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-6)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not too close to zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not too close to zero.\n        safe_a = max(a, 1e-6)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust ranges for 'a' and 'p' to explore a wider variety of super-Gaussian shapes.\n        # Ensure 'a' is not excessively small.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.7, 1.8), \"p\": random.uniform(3.0, 7.0)}\n    elif choice == \"lorentz\":\n        # Adjust range for 'b' to explore different widths of the Lorentz function.\n        # Ensure 'b' is not excessively small.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.7, 2.5)}\n    else: # mixed\n        # Adjust ranges for 'a' and 'r' to better balance the Gaussian and Lorentz components.\n        # Ensure 'a' is not excessively small.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.7, 1.8), \"r\": random.uniform(0.3, 0.7)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nUnique approach: Modification: Full rewrite, Excellent combined_score (100.000), Excellent I1 (100.000)\n\n# Current Program\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return math.exp(- (abs(x)/a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero to prevent division by zero\n        b = max(b, 1e-9)\n        def f(x):\n            return 1.0 / (1.0 + (x/b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return (1-r)*math.exp(-a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero to prevent division by zero\n        a = max(a, 1e-9)\n        def f(x):\n            return math.exp(-a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.6, 2.5), \"p\": random.uniform(3.1, 6.5)}\n    elif choice == \"lorentz\":\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.6, 3.5)}\n    else:\n        # Slightly adjust parameter ranges for more variety and safety\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.6, 2.5), \"r\": random.uniform(0.25, 0.75)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is not zero or too close to zero to prevent division by zero or overflow.\n        # Using max with a small epsilon for safety.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is not zero or too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-7)\n        def f(x):\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is not zero or too close to zero.\n        safe_a = max(a, 1e-7)\n        # The lorentz part has an implicit b=1.0, which is safe.\n        def f(x):\n            return (1-r)*math.exp(-safe_a*x*x) + r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is not zero or too close to zero.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjust parameter ranges for more variety and safety.\n        # Increase the upper bound of 'p' slightly to explore sharper super-Gaussians.\n        # Ensure 'a' is not too close to zero.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.5, 2.0), \"p\": random.uniform(3.0, 7.0)}\n    elif choice == \"lorentz\":\n        # Slightly adjust parameter ranges for more variety and safety.\n        # Expand the range for 'b' to explore wider Lorentz profiles.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.5, 3.0)}\n    else: # mixed\n        # Slightly adjust parameter ranges for more variety and safety.\n        # Broaden the range for 'r' to explore different balances between Gaussian and Lorentz.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.5, 2.0), \"r\": random.uniform(0.2, 0.8)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}