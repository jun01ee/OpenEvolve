{"id": "ce3f21ec-237c-43f3-9ded-d09c0f75acd5", "code": "# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is positive and not too close to zero to prevent division by zero\n        # and maintain numerical stability.\n        safe_a = max(a, 1e-7)\n        # Ensure p is not excessively large, which could lead to overflow or underflow issues.\n        safe_p = min(p, 10.0) # Capped p at 10.0\n        def f(x):\n            # Added a check for abs(x)/safe_a to prevent potential overflow with large p\n            term = abs(x) / safe_a\n            if term > 100 and safe_p > 2: # Heuristic to avoid large intermediate values\n                return 0.0\n            return math.exp(- (term)**safe_p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is positive and not too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-7)\n        def f(x):\n            # The denominator 1.0 + (x/safe_b)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is positive and not too close to zero for the Gaussian term.\n        safe_a = max(a, 1e-7)\n        # Ensure 'r' is within [0, 1] for valid mixing.\n        safe_r = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is 1.0.\n        one_minus_safe_r = max(1.0 - safe_r, 1e-7)\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_safe_r*math.exp(-safe_a*x*x) + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is positive and not too close to zero.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to encourage exploration.\n        # 'a' is kept away from zero, 'p' explores values further from 2.\n        # Increased the upper bound of 'p' slightly to explore sharper super-gaussian shapes.\n        # Also slightly adjusted 'a' range for better spread.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.3, 2.5), \"p\": random.uniform(2.5, 7.5)}\n    elif choice == \"lorentz\":\n        # Adjusted 'b' range to explore values away from zero.\n        # Slightly increased upper bound for 'b' to explore broader Lorentz functions.\n        # Widened the range for 'b' to explore both narrower and broader Lorentz curves.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.3, 4.0)}\n    else: # mixed\n        # Adjusted 'a' and 'r' ranges. 'a' is kept away from zero, 'r' is kept within [0,1].\n        # Slightly widened 'r' range to explore more extreme mixing ratios.\n        # Adjusted 'a' range for Gaussian component to be slightly wider.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.3, 2.5), \"r\": random.uniform(0.05, 0.95)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params", "language": "python", "parent_id": "df8e260a-9b9f-42e4-bd6f-6461e37d8ce7", "generation": 3, "timestamp": 1763629280.890336, "iteration_found": 19, "metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"combined_score": 100.0, "I1": 100.0, "I2": 100.0, "complexity_penalty": 1.0, "smoothness_penalty": 1.0}, "island": 1}, "prompts": {"full_rewrite_user": {"system": "You are an expert in functional analysis and numerical methods.\nProduce small, numerically-safe mutations of the candidate returned by search_algorithm().\nPrefer parameter changes (modify numeric values in the params dict or tweak small constants).\nDo NOT output code that divides by zero or returns NaN/Inf, and do not use heavy Monte-Carlo loops.\nWhen proposing new candidates, either:\n  - return a modified params dictionary (e.g., {\"type\":\"supergauss\",\"a\":1.2,\"p\":4.0}), OR\n  - provide a short, valid Python function f(x) that evaluates safely on [-6,6].\n", "user": "# Current Program Information\n- Fitness: 100.0000\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness unchanged at 100.0000\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: combined_score: 100.0000, I1: 100.0000, I2: 100.0000, complexity_penalty: 1.0000, smoothness_penalty: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 100.0000)\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is positive and not too close to zero to prevent division by zero\n        # and maintain numerical stability.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is positive and not too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-7)\n        def f(x):\n            # The denominator 1.0 + (x/safe_b)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is positive and not too close to zero for the Gaussian term.\n        safe_a = max(a, 1e-7)\n        # Ensure 'r' is within [0, 1] for valid mixing.\n        safe_r = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is 1.0.\n        one_minus_safe_r = max(1.0 - safe_r, 1e-7)\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_safe_r*math.exp(-safe_a*x*x) + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is positive and not too close to zero.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to encourage exploration.\n        # 'a' is kept away from zero, 'p' explores values further from 2.\n        # Increased the upper bound of 'p' slightly to explore sharper super-gaussian shapes.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.4, 2.2), \"p\": random.uniform(2.5, 7.5)}\n    elif choice == \"lorentz\":\n        # Adjusted 'b' range to explore values away from zero.\n        # Slightly increased upper bound for 'b' to explore broader Lorentz functions.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.4, 3.8)}\n    else: # mixed\n        # Adjusted 'a' and 'r' ranges. 'a' is kept away from zero, 'r' is kept within [0,1].\n        # Slightly widened 'r' range to explore more extreme mixing ratios.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.4, 2.2), \"r\": random.uniform(0.1, 0.9)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\nKey features: Performs well on combined_score (100.0000), Performs well on I1 (100.0000), Performs well on I2 (100.0000), Performs well on complexity_penalty (1.0000), Performs well on smoothness_penalty (1.0000)\n\n\n\n# Current Program\n```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is positive and not too close to zero to prevent division by zero\n        # and maintain numerical stability.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(- (abs(x)/safe_a)**p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is positive and not too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-7)\n        def f(x):\n            # The denominator 1.0 + (x/safe_b)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is positive and not too close to zero for the Gaussian term.\n        safe_a = max(a, 1e-7)\n        # Ensure 'r' is within [0, 1] for valid mixing.\n        safe_r = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is 1.0.\n        one_minus_safe_r = max(1.0 - safe_r, 1e-7)\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_safe_r*math.exp(-safe_a*x*x) + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is positive and not too close to zero.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to encourage exploration.\n        # 'a' is kept away from zero, 'p' explores values further from 2.\n        # Increased the upper bound of 'p' slightly to explore sharper super-gaussian shapes.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.4, 2.2), \"p\": random.uniform(2.5, 7.5)}\n    elif choice == \"lorentz\":\n        # Adjusted 'b' range to explore values away from zero.\n        # Slightly increased upper bound for 'b' to explore broader Lorentz functions.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.4, 3.8)}\n    else: # mixed\n        # Adjusted 'a' and 'r' ranges. 'a' is kept away from zero, 'r' is kept within [0,1].\n        # Slightly widened 'r' range to explore more extreme mixing ratios.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.4, 2.2), \"r\": random.uniform(0.1, 0.9)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# initial_program.py\nimport math\nimport random\n\n# Parametric family factory: returns a function f(x) built from parameters.\n# Candidate modules can either provide `params` (dict) or a function `f(x, **kwargs)`.\ndef build_parametric_f(params):\n    # params expected keys: \"type\" and numeric parameters\n    t = params.get(\"type\", \"supergauss\")\n    if t == \"supergauss\":\n        a = float(params.get(\"a\", 1.0))\n        p = float(params.get(\"p\", 4.0))   # p=2 is Gaussian, p>2 super-gauss\n        # Ensure 'a' is positive and not too close to zero to prevent division by zero\n        # and maintain numerical stability.\n        safe_a = max(a, 1e-7)\n        # Ensure p is not excessively large, which could lead to overflow or underflow issues.\n        safe_p = min(p, 10.0) # Capped p at 10.0\n        def f(x):\n            # Added a check for abs(x)/safe_a to prevent potential overflow with large p\n            term = abs(x) / safe_a\n            if term > 100 and safe_p > 2: # Heuristic to avoid large intermediate values\n                return 0.0\n            return math.exp(- (term)**safe_p )\n        return f\n    elif t == \"lorentz\":\n        b = float(params.get(\"b\", 1.0))\n        # Ensure 'b' is positive and not too close to zero to prevent division by zero.\n        safe_b = max(b, 1e-7)\n        def f(x):\n            # The denominator 1.0 + (x/safe_b)**2 is always >= 1.0, so no division by zero here.\n            return 1.0 / (1.0 + (x/safe_b)**2)\n        return f\n    elif t == \"mixed\":\n        a = float(params.get(\"a\", 1.0))\n        r = float(params.get(\"r\", 0.5))\n        # Ensure 'a' is positive and not too close to zero for the Gaussian term.\n        safe_a = max(a, 1e-7)\n        # Ensure 'r' is within [0, 1] for valid mixing.\n        safe_r = max(0.0, min(1.0, r))\n        # Ensure (1-r) is not too close to zero if r is 1.0.\n        one_minus_safe_r = max(1.0 - safe_r, 1e-7)\n        def f(x):\n            # The denominator 1.0 + x*x is always >= 1.0, so no division by zero here.\n            return one_minus_safe_r*math.exp(-safe_a*x*x) + safe_r/(1.0 + x*x)\n        return f\n    else:\n        # fallback safe Gaussian\n        a = float(params.get(\"a\", 1.0))\n        # Ensure 'a' is positive and not too close to zero.\n        safe_a = max(a, 1e-7)\n        def f(x):\n            return math.exp(-safe_a*x*x)\n        return f\n\n# This search_algorithm returns a small parameter dictionary.\ndef search_algorithm():\n    # Provide a diverse starting sample (avoid p=2 exactly to not be Gaussian-first)\n    seed_types = [\"supergauss\", \"lorentz\", \"mixed\"]\n    choice = random.choice(seed_types)\n    if choice == \"supergauss\":\n        # Slightly adjusted ranges for 'a' and 'p' to encourage exploration.\n        # 'a' is kept away from zero, 'p' explores values further from 2.\n        # Increased the upper bound of 'p' slightly to explore sharper super-gaussian shapes.\n        # Also slightly adjusted 'a' range for better spread.\n        params = {\"type\":\"supergauss\", \"a\": random.uniform(0.3, 2.5), \"p\": random.uniform(2.5, 7.5)}\n    elif choice == \"lorentz\":\n        # Adjusted 'b' range to explore values away from zero.\n        # Slightly increased upper bound for 'b' to explore broader Lorentz functions.\n        # Widened the range for 'b' to explore both narrower and broader Lorentz curves.\n        params = {\"type\":\"lorentz\", \"b\": random.uniform(0.3, 4.0)}\n    else: # mixed\n        # Adjusted 'a' and 'r' ranges. 'a' is kept away from zero, 'r' is kept within [0,1].\n        # Slightly widened 'r' range to explore more extreme mixing ratios.\n        # Adjusted 'a' range for Gaussian component to be slightly wider.\n        params = {\"type\":\"mixed\", \"a\": random.uniform(0.3, 2.5), \"r\": random.uniform(0.05, 0.95)}\n    # OpenEvolve can mutate the `params` dict or replace it with other dicts. Return it.\n    return params\n```"]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}